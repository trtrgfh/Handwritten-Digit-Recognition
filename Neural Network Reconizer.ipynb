{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1231e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.load(\"data/X.npy\")\n",
    "    y = np.load(\"data/y.npy\")\n",
    "    return split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size = 0.7):\n",
    "    \"\"\"\n",
    "    Return a dictionary containing the traning set, validation set and the test set\n",
    "    \"\"\"\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, train_size=0.5)\n",
    "    data = {\"train\": (X_train, y_train), \"val\": (X_val, y_val), \"test\": (X_test, y_test)}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe89da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn():\n",
    "    # Since each image is 20 by 20, the input is 400\n",
    "    tf.random.set_seed(1234)\n",
    "    model = Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(400,)),\n",
    "            Dense(25, activation = 'relu', name = 'layer1'),\n",
    "            Dense(15, activation = 'relu', name = 'layer2'),\n",
    "            Dense(10, activation = 'linear', name = 'layer3')\n",
    "        ], name = \"nn_model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ab275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(data, learning_rate, epochs):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_lr = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in epochs:\n",
    "        for l in learning_rate:\n",
    "            model = create_nn()\n",
    "            model.compile(\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=l),\n",
    "            )\n",
    "            model.fit(\n",
    "                data['train'][0], data['train'][1],\n",
    "                epochs=epoch\n",
    "            )\n",
    "            train_prediction, train_acc = predict(model, data['train'][0], data['train'][1])\n",
    "            # print(\"epochs: {}, learning rate: {}, train_acc: {}\".format(epoch, l, train_acc))\n",
    "            train_prediction, val_acc = predict(model, data['val'][0], data['val'][1])\n",
    "            # print(\"epochs: {}, learning rate: {}, val_acc: {}\".format(epoch, l, val_acc))\n",
    "\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_lr = l\n",
    "                best_model = model\n",
    "\n",
    "    print(\"best epochs: {}, best learning rate: {}\".format(best_epoch, best_lr))\n",
    "\n",
    "    train_prediction, train_acc = predict(best_model, data['train'][0], data['train'][1])\n",
    "    print(\"train_acc: {:.4f}\".format(train_acc))\n",
    "\n",
    "    train_prediction, val_acc = predict(best_model, data['val'][0], data['val'][1])\n",
    "    print(\"val_acc: {:.4f}\".format(val_acc))\n",
    "\n",
    "    test_prediction, test_acc = predict(best_model, data['test'][0], data['test'][1])\n",
    "    print(\"test_acc: {:.4f}\".format(test_acc))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a79944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    m, n = X.shape\n",
    "    prediction = model.predict(X.reshape(-1, 400))\n",
    "    # if you need a probability output then use prediction = tf.nn.softmax(prediction)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    prediction = prediction.reshape(m, 1)\n",
    "    accuracy = np.sum((prediction == y) / m)\n",
    "\n",
    "    return prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # The data contains 5000 examples of handwritten digits. Each example is a 20 pixel by 20 pixel grayscale image\n",
    "    # Each 20 by 20 image is unrolled into a 400 dimensional vector.\n",
    "    data = load_data()\n",
    "\n",
    "    # learning_rate = [0.001, 0.01, 0.05]\n",
    "    # epochs = [10, 25, 40, 60]\n",
    "    learning_rate = [0.001]\n",
    "    epochs = [40]\n",
    "    best_model = select_model(data, learning_rate, epochs)\n",
    "    print(f\"{display_errors(best_model, data['test'][0], data['test'][1])} errors out of {len(data['test'][0])} images in test set\")\n",
    "    plt.show()\n",
    "\n",
    "    # random_idx = random.sample(range(0, len(data['test'][0])), 10)\n",
    "    # example = data['test'][1][random_idx]\n",
    "    # ex_pred, acc = predict(best_model, data['test'][0], data['test'][1])\n",
    "    # print(example.T)\n",
    "    # print(ex_pred[random_idx].T)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e576b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
